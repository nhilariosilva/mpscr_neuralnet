{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23f6d359-61b3-4297-aed2-6dce09f3e9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741798693.740530  645670 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741798693.744075  645670 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "/home/natan/.pyenv/versions/3.10.16/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "I0000 00:00:1741798695.514933  645670 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4114 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 6GB Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "\n",
    "from time import time\n",
    "\n",
    "from silence_tensorflow import silence_tensorflow\n",
    "silence_tensorflow()\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import models, layers, initializers, optimizers, losses\n",
    "from keras.utils import to_categorical\n",
    "from tqdm.keras import TqdmCallback\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config = config)\n",
    "\n",
    "import os, shutil\n",
    "import json\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb383b7-e43e-4d58-8145-92d1fbe9a860",
   "metadata": {},
   "source": [
    "# Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f722b5da-0380-4bcd-8499-bb72b99b725a",
   "metadata": {},
   "source": [
    "In this notebook, we aim to investigate the Fashion-MNIST problem and formulate a Convolutional Neural Network (CNN) that is capable of prediction the correct class of clothing objects with high accuracy rates. For the model to be similar to what we will be applying in the context of the cure rate models, we shall only consider the first 5 classes of clothing in this case. We are using as a main guide reference, the tutorial: https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-fashion-mnist-clothing-classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3ef555e-32fa-47d2-a489-c1fae018980f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdaeed2b-ea75-4e08-a909-1fd1c3dc6f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneHot Categories: [array([0, 1, 2, 3, 4], dtype=uint8)]\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "i_valid_train = pd.Series(train_labels).isin([0,1,2,3,4]).to_numpy()\n",
    "i_valid_test = pd.Series(test_labels).isin([0,1,2,3,4]).to_numpy()\n",
    "\n",
    "# Filters to take only the images with labels in [0, 1, 2, 3, 4]\n",
    "train_images = train_images[i_valid_train]\n",
    "train_images = train_images / np.max(train_images)\n",
    "train_shape = train_images.shape\n",
    "# Adds one more dimension for keras to identify the \"colors\" dimension\n",
    "train_images = np.reshape(train_images, (train_shape[0], train_shape[1], train_shape[2], 1))\n",
    "\n",
    "test_images = test_images[i_valid_test]\n",
    "test_images = test_images / np.max(test_images)\n",
    "test_shape = test_images.shape\n",
    "# Adds one more dimension for keras to identify the \"colors\" dimension\n",
    "test_images = np.reshape(test_images, (test_shape[0], test_shape[1], test_shape[2], 1))\n",
    "\n",
    "train_labels = train_labels[i_valid_train]\n",
    "test_labels = test_labels[i_valid_test]\n",
    "\n",
    "# -------------------- Separates the dataset into train, val and test --------------------\n",
    "val_images = train_images[25000:, :, :, :]\n",
    "train_images = train_images[:25000, :, :, :]\n",
    "\n",
    "val_labels = train_labels[25000:]\n",
    "train_labels = train_labels[:25000]\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit( np.transpose([train_labels]) )\n",
    "print(\"OneHot Categories: {}\".format(ohe.categories_))\n",
    "\n",
    "train_y = ohe.transform( np.transpose([train_labels]) ).toarray()\n",
    "val_y = ohe.transform( np.transpose([val_labels]) ).toarray()\n",
    "test_y = ohe.transform( np.transpose([test_labels]) ).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5057650-c2b9-468f-8cc3-39a30075d39b",
   "metadata": {},
   "source": [
    "First, we will consider the case where there is a single convolutional layer for the images, followed by two dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11677d85-4a79-4537-955b-b6c95343266e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelMNIST(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "            \n",
    "    def define_structure(self, shape_input, seed = 1):\n",
    "        self.shape_input = shape_input\n",
    "        \n",
    "        # Gera uma imagem inteira de zeros com as dimensões do modelo\n",
    "        dummy_input = keras.layers.Input(shape = self.shape_input)\n",
    "        \n",
    "        initializer = initializers.HeUniform(seed = seed)\n",
    "        \n",
    "        self.convolution1 = keras.layers.Conv2D(filters = 32, kernel_size = [3,3], padding = \"same\", activation = tf.nn.leaky_relu,\n",
    "                                                kernel_initializer = initializer, dtype = tf.float32)\n",
    "        self.pooling1 = keras.layers.MaxPool2D(pool_size = [3,3], strides = 2)\n",
    "    \n",
    "        self.flatten = keras.layers.Reshape(target_shape=(-1,))\n",
    "        self.dense1 = keras.layers.Dense(units = 100, activation = tf.nn.relu, dtype = tf.float32)\n",
    "        self.dense2 = keras.layers.Dense(units = 5, dtype = tf.float32, activation = \"softmax\", use_bias = False)\n",
    "\n",
    "        # Initialize the model weights (if not called beforehand, the method .get_weights() returns an empty list)\n",
    "        self(dummy_input)\n",
    "        \n",
    "    def call(self, x_input):\n",
    "        x = self.convolution1(x_input)\n",
    "        x = self.pooling1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = tf.cast(x, dtype = tf.float64)\n",
    "        return x\n",
    "    \n",
    "    def copy(self):\n",
    "        new_model = ModelMNIST()\n",
    "        new_model.define_structure(shape_input = self.shape_input)\n",
    "        new_model.set_weights(self.get_weights())\n",
    "        return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75fbce3d-54d8-4e2b-b787-2392f5a87821",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelMNIST(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "            \n",
    "    def define_structure(self, shape_input, seed = 1):\n",
    "        self.shape_input = shape_input\n",
    "        \n",
    "        # Gera uma imagem inteira de zeros com as dimensões do modelo\n",
    "        dummy_input = keras.layers.Input(shape = self.shape_input)\n",
    "        \n",
    "        initializer = initializers.HeUniform(seed = seed)\n",
    "        \n",
    "        self.convolution1 = keras.layers.Conv2D(filters = 16, kernel_size = [3,3], padding = \"same\", activation = tf.nn.leaky_relu,\n",
    "                                                kernel_initializer = \"he_uniform\", dtype = tf.float32)\n",
    "        self.pooling1 = keras.layers.MaxPool2D(pool_size = [2,2], strides = 2)\n",
    "        self.convolution2 = keras.layers.Conv2D(filters = 32, kernel_size = [3,3], padding = \"same\", activation = tf.nn.leaky_relu,\n",
    "                                                kernel_initializer = \"he_uniform\", dtype = tf.float32)\n",
    "        self.pooling2 = keras.layers.MaxPool2D(pool_size = [2,2], strides = 2)\n",
    "    \n",
    "        self.flatten = keras.layers.Reshape(target_shape=(-1,))\n",
    "        self.dense1 = keras.layers.Dense(units = 64, activation = tf.nn.relu, dtype = tf.float32)\n",
    "        self.dense2 = keras.layers.Dense(units = 5, dtype = tf.float32, activation = \"softmax\", use_bias = False)\n",
    "\n",
    "        # Initialize the model weights (if not called beforehand, the method .get_weights() returns an empty list)\n",
    "        self(dummy_input)\n",
    "        \n",
    "    def call(self, x_input):\n",
    "        x = self.convolution1(x_input)\n",
    "        x = self.pooling1(x)\n",
    "        x = self.convolution2(x)\n",
    "        x = self.pooling2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = tf.cast(x, dtype = tf.float64)\n",
    "        return x\n",
    "    \n",
    "    def copy(self):\n",
    "        new_model = ModelMNIST()\n",
    "        new_model.define_structure(shape_input = self.shape_input)\n",
    "        new_model.set_weights(self.get_weights())\n",
    "        return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79d90c43-745f-40df-8a79-4c96df8d4335",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████████████████████▌                                                                                              | 30/100 [00:18<00:43,  1.63epoch/s, loss=0.169, val_loss=0.205]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x791900059db0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ModelMNIST()\n",
    "model.define_structure(shape_input = train_images[0].shape, seed = 10)\n",
    "\n",
    "callbacks = [ TqdmCallback(verbose=0) ]\n",
    "\n",
    "# Parada precoce (Early stopping) - Evita overfitting e agiliza o treinamento\n",
    "es = keras.callbacks.EarlyStopping(monitor = 'val_loss',\n",
    "                                   mode = \"min\",\n",
    "                                   min_delta = 0.0,\n",
    "                                   patience = 5,\n",
    "                                   restore_best_weights = True)\n",
    "callbacks.append(es)\n",
    "\n",
    "model.compile(\n",
    "    optimizer = optimizers.Adam(learning_rate = 0.001),\n",
    "    loss = \"categorical_crossentropy\",\n",
    "    run_eagerly = False\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_images, train_y,\n",
    "    epochs = 100,\n",
    "    verbose = 0,\n",
    "    callbacks = callbacks,\n",
    "    batch_size = 1024,\n",
    "    shuffle = True,\n",
    "    validation_data = (val_images, val_y)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0bb66a7-6128-4212-8de8-c41746b0b569",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_p_pred = model.predict(train_images, verbose = False)\n",
    "val_labels_p_pred = model.predict(val_images, verbose = False)\n",
    "test_labels_p_pred = model.predict(test_images, verbose = False)\n",
    "\n",
    "train_labels_pred = ohe.inverse_transform( train_labels_p_pred ).flatten()\n",
    "val_labels_pred = ohe.inverse_transform( val_labels_p_pred ).flatten()\n",
    "test_labels_pred = ohe.inverse_transform( test_labels_p_pred ).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db14d5d3-e3b6-4f55-9d7e-dd2d891222a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Accuracy --------\n",
      "Train: 0.94672\n",
      "Validation: 0.9288\n",
      "Test: 0.9232\n",
      "-------- AUC macro --------\n",
      "Train: 0.9956167771495312\n",
      "Validation: 0.9932464148709608\n",
      "Test: 0.9921239000000002\n"
     ]
    }
   ],
   "source": [
    "print(\"-------- Accuracy --------\")\n",
    "print(\"Train: {}\".format(accuracy_score(train_labels, train_labels_pred)))\n",
    "print(\"Validation: {}\".format(accuracy_score(val_labels, val_labels_pred)))\n",
    "print(\"Test: {}\".format(accuracy_score(test_labels, test_labels_pred)))\n",
    "\n",
    "print(\"-------- AUC macro --------\")\n",
    "print(\"Train: {}\".format( roc_auc_score(train_labels, train_labels_p_pred, multi_class = \"ovr\") ))\n",
    "print(\"Validation: {}\".format( roc_auc_score(val_labels, val_labels_p_pred, multi_class = \"ovr\") ))\n",
    "print(\"Test: {}\".format( roc_auc_score(test_labels, test_labels_p_pred, multi_class = \"ovr\") ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a11f6aae-5159-4fd6-957a-d1716a382894",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelMNIST_cureprobs(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "            \n",
    "    def define_structure(self, shape_input, seed = 1):\n",
    "        self.shape_input = shape_input\n",
    "        \n",
    "        # Gera uma imagem inteira de zeros com as dimensões do modelo\n",
    "        dummy_input = keras.layers.Input(shape = self.shape_input)\n",
    "        \n",
    "        initializer = initializers.HeNormal(seed = seed)\n",
    "        # initializer = tf.random_normal_initializer(stddev = 0.005) # IF CONVERGENCE FAILS, RETURN TO THIS INITIALIZER!!!\n",
    "        \n",
    "        self.convolution1 = keras.layers.Conv2D(filters = 4, kernel_size = [5,5], padding = \"same\", activation = tf.nn.leaky_relu,\n",
    "                                                kernel_initializer = initializer, dtype = tf.float32)\n",
    "        self.pooling1 = keras.layers.MaxPool2D(pool_size = [2,2], strides = 2)\n",
    "        # self.convolution2 = keras.layers.Conv2D(filters = 12, kernel_size = [5,5], padding = \"same\", activation = tf.nn.leaky_relu,\n",
    "        #                                         kernel_initializer = initializer, dtype = tf.float32)\n",
    "        # self.pooling2 = keras.layers.MaxPool2D(pool_size = [2,2], strides = 2)\n",
    "        # self.convolution3 = keras.layers.Conv2D(filters = 32, kernel_size = [5,5], padding = \"same\", activation = tf.nn.leaky_relu,\n",
    "        #                                         kernel_initializer = initializer, dtype = tf.float32)\n",
    "        # self.pooling3 = keras.layers.MaxPool2D(pool_size = [2,2], strides = 2)\n",
    "        \n",
    "        self.flatten = keras.layers.Reshape(target_shape=(-1,))\n",
    "        self.dense1 = keras.layers.Dense(units = 128, activation = tf.nn.tanh, dtype = tf.float32)\n",
    "        self.dense2 = keras.layers.Dense(units = 5, dtype = tf.float32, activation = \"softmax\", use_bias = False)\n",
    "        \n",
    "        # Initialize the model weights (if not called beforehand, the method .get_weights() returns an empty list)\n",
    "        self(dummy_input)\n",
    "\n",
    "        \n",
    "    def call(self, x_input):\n",
    "        x = self.convolution1(x_input)\n",
    "        x = self.pooling1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = tf.cast(x, dtype = tf.float64)\n",
    "        return x\n",
    "    \n",
    "    def copy(self):\n",
    "        new_model = ModelMNIST()\n",
    "        new_model.define_structure(shape_input = self.shape_input)\n",
    "        new_model.set_weights(self.get_weights())\n",
    "        return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a9c0f3d-18a2-41f1-b112-558b6f96a167",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|██████████████████████████████████████████████████████████                                                                             | 43/100 [00:16<00:21,  2.60epoch/s, loss=0.131, val_loss=0.211]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x79191c0c9a50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = ModelMNIST_cureprobs()\n",
    "model2.define_structure(shape_input = train_images[0].shape, seed = 10)\n",
    "\n",
    "callbacks = [ TqdmCallback(verbose=0) ]\n",
    "\n",
    "# Parada precoce (Early stopping) - Evita overfitting e agiliza o treinamento\n",
    "es = keras.callbacks.EarlyStopping(monitor = 'val_loss',\n",
    "                                   mode = \"min\",\n",
    "                                   min_delta = 0.0,\n",
    "                                   patience = 5,\n",
    "                                   restore_best_weights = True)\n",
    "callbacks.append(es)\n",
    "\n",
    "model2.compile(\n",
    "    optimizer = optimizers.Adam(learning_rate = 0.001),\n",
    "    loss = \"categorical_crossentropy\",\n",
    "    run_eagerly = False\n",
    ")\n",
    "\n",
    "model2.fit(\n",
    "    train_images, train_y,\n",
    "    epochs = 100,\n",
    "    verbose = 0,\n",
    "    callbacks = callbacks,\n",
    "    batch_size = 1024,\n",
    "    shuffle = True,\n",
    "    validation_data = (val_images, val_y)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad68763a-d66e-43e7-be91-464001adf804",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_p_pred2 = model2.predict(train_images, verbose = False)\n",
    "val_labels_p_pred2 = model2.predict(val_images, verbose = False)\n",
    "test_labels_p_pred2 = model2.predict(test_images, verbose = False)\n",
    "\n",
    "train_labels_pred2 = ohe.inverse_transform( train_labels_p_pred ).flatten()\n",
    "val_labels_pred2 = ohe.inverse_transform( val_labels_p_pred ).flatten()\n",
    "test_labels_pred2 = ohe.inverse_transform( test_labels_p_pred ).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01b26ec1-3e4d-4222-bbc6-7a2743e70e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Accuracy --------\n",
      "Train: 0.94544\n",
      "Validation: 0.9238\n",
      "Test: 0.9266\n",
      "-------- AUC macro --------\n",
      "Train: 0.9967475762475388\n",
      "Validation: 0.9928077362993948\n",
      "Test: 0.9922133500000001\n"
     ]
    }
   ],
   "source": [
    "print(\"-------- Accuracy --------\")\n",
    "print(\"Train: {}\".format(accuracy_score(train_labels, train_labels_pred2)))\n",
    "print(\"Validation: {}\".format(accuracy_score(val_labels, val_labels_pred2)))\n",
    "print(\"Test: {}\".format(accuracy_score(test_labels, test_labels_pred2)))\n",
    "\n",
    "print(\"-------- AUC macro --------\")\n",
    "print(\"Train: {}\".format( roc_auc_score(train_labels, train_labels_p_pred2, multi_class = \"ovr\") ))\n",
    "print(\"Validation: {}\".format( roc_auc_score(val_labels, val_labels_p_pred2, multi_class = \"ovr\") ))\n",
    "print(\"Test: {}\".format( roc_auc_score(test_labels, test_labels_p_pred2, multi_class = \"ovr\") ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
